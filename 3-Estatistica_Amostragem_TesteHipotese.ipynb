{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "# Vamos falar um pouco sobre AMOSTRA\n",
    "![amostra](https://www.displayr.com/wp-content/uploads/2018/07/dreamstime_s_97267612_780x480.jpg)\n",
    "\n",
    "## Inferência estatística\n",
    "É um conjunto de técnicas que visam estudar uma população através de evidências fornecidas por uma amostra (sample). Com isso, podemos inferir coisas a respeito da população.\n",
    "\n",
    "Tudo o que fazemos na vida é tomar decisões baseadas em informações que coletamos. Por exemplo: se quero saber se devo ou não levar um guarda-chuva comigo, olho pela janela para ver se o tempo está nublado. Se eu quiser saber do futuro, posso olhar um site com a previsão do tempo. Isso foi uma tomada de decisão.\n",
    "\n",
    "Uma fábrica de medicamentos quer saber se um novo remédio é eficiente para combater a dor de cabeça. O melhor jeito de saber isso é oferecendo o medicamento pra toda a população e avaliando se isso resolveu a dor de cabeça de cada pessoa, mas isso é pouco factível... Seria muito caro e pouco prático.\n",
    "\n",
    "Ou uma fábrica de peças de carro quer saber se um lote de peças é defeituoso ou não. Para fazer um teste de resistência, é necessário estressar a peça até que ela seja destruída. Então, para saber se um lote tem peças defeituosas, seria necessário destruir todo o lote no processo. Isso nem faz sentido.\n",
    "\n",
    "**Como resolver?**\n",
    "\n",
    "## Amostra\n",
    "Com algumas peças do lote, conseguimos afirmar com alguma certeza se o lote inteiro é defeituoso. Com algumas pessoas, conseguimos determinar a eficácia do novo remédio. O nome desse pequeno pedaço é amostra.\n",
    "\n",
    "Uma amostra é uma parte da população que é capaz de representar o todo para extrair algumas métricas. Quanto maior for a sua amostra, maior a sua certeza em relação às métricas da população. Mas a ideia da amostra é justamente não precisar da população inteira e aceitar um grau de incerteza em cima das métricas.\n",
    "\n",
    "A chave que faz com que a amostra seja representativa da população é a seleção aleatória (aliada a um bom entendimento da população). Imagine que um aplicativo que funciona no Brasil vai lançar uma nova funcionalidade e decide testá-la com uma amostra de usuários da cidade de São Paulo. Ainda que a amostra tenha sido escolhida aleatoriamente, é difícil que os resultados observados sejam os mesmos obtidos uma vez que a nova funcionalidade seja lançada para os usuários de todo o Brasil. Isso acontece porque São Paulo não representa a população do Brasil. O ideal seria que várias pessoas de todos os lugares que o aplicativo atua tivessem algum tipo de representatividade.\n",
    "\n",
    "## Como selecionar/extrair uma amostra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "# amostras de 50 jogadas de moedas\n",
    "jogadas = pandas.read_csv(\"https://databootcamp.nyc3.digitaloceanspaces.com/jogadas.csv\")\n",
    "jogadas[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jogadas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Primeiro vamos encontrar o desvio padrão dessa amostra</font>\n",
    "\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/atrasada-relogio-pulso-1116-1400x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O que costumo fazer a seguir é olhar a distribuição!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experimentos = jogadas.exp\n",
    "experimentos.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos pegar uma amostra usando *sample*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra = experimentos.sample(frac=0.01)\n",
    "amostra.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uma coisa que sempre vemos é se as curvas estão parecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentos.plot.kde()\n",
    "amostra.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viu como - nesse caso - 1% dos dados conseguiu trazer um desenho de distribuição semelhante à original?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outra forma é ver as médias dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experimentos.mean())\n",
    "print(amostra.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Junto com o desvio padrão a gente consegue ver se os erros continuam iguais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experimentos.std())\n",
    "print(amostra.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validando a amostra: Intervalo de Confiança + Margem de erro (a largura entre a média e os valores do intervalo)\n",
    "\n",
    "Aqui a parte de \"aceitar incerteza\" sobre os dados faz mais sentido. O nível de confiança é a frequência com a qual o intervalo observado contém o parâmetro real de interesse quando o experimento é repetido várias vezes. \n",
    "Os intervalos de confiança são tipicamente estabelecidos no nível de confiança de 95%.\n",
    "\n",
    "Quanto maiores os intervalos de confiança, maior a incerteza sobre o dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy\n",
    "\n",
    "mu = numpy.mean(jogadas.exp)\n",
    "sigma = numpy.std(jogadas.exp)\n",
    "\n",
    "print(mu)\n",
    "print(sigma)\n",
    " \n",
    "#A location (loc) é uma média.\n",
    "#A escala (scale) é o desvio padrão.\n",
    " \n",
    "stats.norm.interval(0.95, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, nesse caso 95% dos valores estão nesse range porque **mu** ± **sigma** está dentro do intervalo 18,08 e 31,95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Margem de erro não é mágica!\n",
    "\n",
    "Existe um valor *Z* para cada nível de confiança pré estabelecido e para 95% (padrão usado) temos 1,96\n",
    "\n",
    "| Nível de Confiança | Valor Z |\n",
    "|--------------------|---------|\n",
    "| 80%                | 1,28    |\n",
    "| 90%                | 1,64    |\n",
    "| 95%                | 1,96    |\n",
    "| 99%                | 2,58    |\n",
    "\n",
    "Esses valores são exatamente os desvios padrão em relação à média da distribuição Normal padrão (média 0 e variância 1)! Isso significa que valores que estejam até +1,96 e -1,96 de distância da média da distribuição correspondem a 95% dos dados quando eles seguem a distribuição normal!\n",
    "\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/normal-distrubution-large.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"limite inferior = {}\".format(mu - 1.96 * sigma))\n",
    "print(\"limite superior = {}\".format(mu + 1.96 * sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de Hipótese para comparação entre amostras\n",
    "Teste de hipóteses é o nome formal do processo de decisão a partir de dados. Nas empresas, é conhecido como teste AB.\n",
    "\n",
    "Na prática, estamos apenas testando se as amostras de dois grupos vem da mesma distribuição. A forma mais simples de fazer isso é assumir que as duas amostras vêm da mesma população e avaliar se os parâmetros delas são iguais ou não. Lembram que a Normal é caracterizada por dois parâmetros: a média e a variância? Em um teste de hipóteses para medidas que vem da Normal, podemos testar se a média de uma amostra é estatisticamente igual à media de outra amostra.\n",
    "\n",
    "Nesses testes sempre partimos de uma visão conservadora, de que as coisas não mudam, e buscamos evidências fortes o suficiente que nos façam acreditar no contrário. Isso é relacionado aos erros tipo I e tipo II (CALMA!).\n",
    "\n",
    "A visão conservadora é chamada de hipótese nula. Suponha que queremos testar se a altura de homens é igual a altura de mulheres. A visão conservadora é que sim. Se encontrarmos evidências fortes o suficiente que nos façam não aceitar essa visão, aceitamos a hipótese alternativa.\n",
    "\n",
    "Em estatisquês, queremos dizer que:\n",
    "$$H_0 (hipótese \\ nula): média \\ da \\ altura \\ de \\ homens = média \\ da \\ altura \\ de \\ mulheres$$\n",
    "$$H_1 (hipótese \\ alternativa): média \\ da \\ altura \\ de \\ homens \\neq média \\ da \\ altura \\ de \\ mulheres$$\n",
    "\n",
    "Sabemos que as médias de alguma população seguem a distribuição normal por causa do Teorema do Limite central. então estamos testando se as alturas de homens e mulheres seguem a mesma distribuição!\n",
    "\n",
    "![teste de hipóteses](https://i1.wp.com/statisticsbyjim.com/wp-content/uploads/2018/07/TypesErrorHypothesisTests.png?resize=600%2C400)\n",
    "\n",
    "Uma vez que temos as hipóteses formuladas, podemos coletar dados. Com os dados, calculamos as estatísticas do teste e o p-valor. A estatística do teste é o valor de referência calculado para aquela distribuição. Por exemplo, o 1,96 da normal é o valor correspondente a 95% de cobertura em testes bicaudais (quando a hipótese alternativa é do tipo $\\neq$). Depois de coletar os dados do experimento, calculamos a estatística do teste, que é um valor como o 1,96 e que será usado para calcular a probabilidade de que a hipótese nula seja verdadeira. Assim sendo, o p-valor é a probabilidade de, assumindo que a hipótese nula é verdadeira, encontremos valores de estatística de teste como o que encontramos (ou mais extremos). Quando o p-valor é muito baixo, a probabilidade de observar resultados como os que observamos são muito baixos e, portanto, temos mais evidências de que os resultados que vimos não são ao acaso (ou seja, que a hipótese nula é falsa)!\n",
    "\n",
    "Como essa comparação acontece depois de termos os dados em mãos, é muito fácil cair na tentação de dizer que um experimento não rejeita a hipótese nula para 95% de confiança, mas rejeita para 90% (uai, é só trocar o valor de comparação, não é mesmo? NÃO!!!!). Usamos a confiança exigida para calcular a amostra mínima necessária e outras coisas do nosso desenho de experimento. Portanto, trocar um parâmetro assim no meio do caminho é uma violação das premissas do teste, o que pode invalidar completamente os resultados.\n",
    "\n",
    "### Erro tipo I e Erro tipo II\n",
    "Com essas hipóteses e esse teste, podemos tomar quatro tipos de decisões:\n",
    "\n",
    "|                    | $H_0$ é verdadeira   | $H_0$ é falsa         |\n",
    "|--------------------|----------------------|-----------------------|\n",
    "| Rejeito $H_0$      | Erro tipo I (\\alpha) | Correto               |\n",
    "| Não rejeito $H_0$  | Correto              | Erro tipo II (\\beta)  |\n",
    "\n",
    "Idealmente, queremos controlar o erro tipo I e II. Na prática, fixamos o erro tipo I em 5%, o que nos leva aos 95% de confiança que vimos há pouco! Tudo tem um motivo.\n",
    "\n",
    "$1-\\beta$ é chamado poder do teste. Se a nossa amostra for grande o suficiente, nosso poder será maior. É o cenário que buscamos (:\n",
    "\n",
    "### T de Student\n",
    "#### Pausa pro momento de história\n",
    "\n",
    "![Guinness geladinha](https://i0.wp.com/www.eatthis.com/wp-content/uploads/2019/03/dark-colored-guinness-in-glass.jpg?fit=1200%2C879&ssl=1)\n",
    "\n",
    "Diz a história que a distribuição T de Student apareceu pela primeira vez em um artigo escrito por William Sealy Gosset para a revista Biometrila em 1908. Porém, William assinou o artigo com o pseudônimo Student (estudante, em inglês) ao invés de assinar com o seu nome. Isso aconteceu porque William trabalhava para a cervejaria Guinness na época e precisava fazer testes de qualidade de fermentos com amostragem reduzida (em que não é muito óbvio conseguir estimadores razoáveis do desvio padrão). A cervejaria não permitia que funcionários publicassem trabalhos científicos porque acreditava que isso revelaria algum tipo de segredo de negócio, o que fez com que William não usasse seu nome em uma publicação super importante na história da estatística!\n",
    "\n",
    "#### E voltando...\n",
    "O teste t de Student ou somente teste t é um teste de hipótese que usa conceitos estatísticos para rejeitar ou não uma hipótese nula quando a estatística de teste segue uma distribuição t de Student. A distribuição T se parece muito com a distribuição Normal (e, de fato, ambas assumem os mesmo valores para amostras suficientemente grandes).\n",
    "\n",
    "![T vs Normal](https://cdn.analystprep.com/cfa-level-1-exam/wp-content/uploads/2019/10/05102016/page-157.jpg)\n",
    "\n",
    "Uma vantagem da distribuição T em relação à Normal é que não há a necessidade de se conhecer e nem fazer premissas sobre a variância da população de origem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos cursos de estatística, aprendemos a calcular estatística de teste e \n",
    "# p-valor na mão, mas por sorte a tecnologia funciona a nosso favor!\n",
    "stats.ttest_ind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar o outro dataset de jogadas\n",
    "jogadas2 = pandas.read_csv('jogadas2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra1 = jogadas.exp.sample(frac=0.1)\n",
    "amostra2 = jogadas2.exp.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s é a estatística do teste e pvalue é o p-valor correspondente\n",
    "s, pvalue = stats.ttest_ind(amostra1, amostra2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, pvalue = stats.ttest_ind(amostra1, amostra2)\n",
    "\n",
    "if(pvalue >= 0.01):\n",
    "    print(\"Aceito que as médias são iguais estatisticamente com 99% de confianca!\")\n",
    "    print(amostra1.mean(), amostra2.mean())\n",
    "else:\n",
    "    print(\"Rejeito que as médias são iguais estatisticamente com 99% de confianca!\")\n",
    "    print(amostra1.mean(), amostra2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra1.plot.kde()\n",
    "amostra2.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos ver no titanic as amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pandas.read_csv(\"https://databootcamp.nyc3.digitaloceanspaces.com/titanic_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pegamos amostras somente com as colunas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra1 = titanic.sample(frac=0.1).select_dtypes(include=[numpy.number])\n",
    "amostra2 = titanic.sample(frac=0.4).select_dtypes(include=[numpy.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Utilize teste t de student para validar estatisticamente as amostras *amostra1* e *amostra2*</font>\n",
    "\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/atrasada-relogio-pulso-1116-1400x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlação entre as amostras\n",
    "\n",
    "Outro ponto que podemos validar é se a correlação entre as colunas do dado real e das amostras se mantiveram. Essa correlação é um índice que pode variar entre -1 e 1 e indica se uma coluna influencia positivamente ou negativamente no valor da outra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Pandas já existe uma função que utiliza a correlação de **Pearson** por padrão.\n",
    "\n",
    "A correlação de Pearson é muito boa para capturar uma relação linearmente positiva ou negativa entre conjuntos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa tabela, a linha diagonal sempre será 1 porque a própria coluna incluencia diretamente no valor dela mesma. Podemos fazer um teste para ver o valor -1 aparecer multiplicando uma coluna por -1. Vamos tentar com a coluna **Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"InverseAge\"] = titanic[\"Age\"]*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos comparar somente a correlação de uma coluna com a outra agora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Age\"].corr(titanic[\"InverseAge\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos mostrar essas correlações de uma forma mais visual com uma alteração de estilo no DataFrame. Note que o campo **Age** ficou com correlação negativa com **InverseAge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic.corr().style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso você queira mudar a correlação para encontrar correlações não lineares existem outros algoritmos como a correlação de **Spearman**. Esse algoritmo usa um rankeamento para identificar correlações ao invés de verificar se são lineares. No pandas pode ser usada somente alterando uma configuração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.corr(\"spearman\").style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vemos a diferença de uma correlação linear e não linear na seguinte imagem. Como Spearman usa um ranking ele verifica se os pontos estão subindo, enquanto Pearson precisa que os pontos subam linearmente para considerar correlato.\n",
    "\n",
    "![spearmanxpearson](https://databootcamp.nyc3.digitaloceanspaces.com/img/spearmanxpearson.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Com essas correlações você consegue pensar em boas colunas para predizer **Survived**?</font>\n",
    "\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/atrasada-relogio-pulso-1116-1400x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pensando em visualização, existem alguns projetos como o *Pandas Profiling* que ajudam nessa visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(titanic, explorative=True)\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inclusive você pode exportar esse relatório para uma página html e outros formatos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(\"titanic_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
