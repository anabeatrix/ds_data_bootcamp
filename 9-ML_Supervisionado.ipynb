{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado Supervisionado\n",
    "\n",
    "É o aprendizado em que passamos para o modelo algumas **features** e **labels** em um treinamento. Depois disso, ele consegue inferir **labels** ainda não conhecidas baseadas em novas **features**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "titanic = pandas.read_csv(\"https://databootcamp.nyc3.digitaloceanspaces.com/titanic_4.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino e Teste\n",
    "\n",
    "Para treinar algoritmos de machine learning precisamos dividir nosso dataset entre treino e teste. No treino ele vai aprender o comportamento dos dados para tentar prever no teste as labels. Não podemos passar para o algoritmo todos os dados durante o treinamento porque senão não temos como saber se ele vai conseguir prever dados que ele nunca viu corretamente.\n",
    "\n",
    "![train_test](https://databootcamp.nyc3.digitaloceanspaces.com/img/Train-Test-Data-Split.png)\n",
    "\n",
    "Normalmente utilizamos proporção em que 70% do dado vai para o treino e 30% fica para o teste. Para essa divisão o **Sklearn** já tem uma função pronta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos determinar que a label seja **Age**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para essa função já temos que passar separadamente o que é **feature** e o que é **label**. Vamos dizer que a nossa label seja o campo **Age** porque vamos querer prever a melhor forma de preencher ele, mas só podemos pegar as idades preenchidas para treinar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_without_na = titanic.dropna()\n",
    "titanic_without_na.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos escolher algumas features que **não** tenham relação com **Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cols = [\n",
    "    \"Pclass\",\n",
    "    \"Sex_female\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"Relatives\",\n",
    "    \"Embarked_C\",\n",
    "    \"Embarked_Q\",\n",
    "    \"Embarked_S\",\n",
    "    \"Fare\",\n",
    "    \"Survived\"\n",
    "]\n",
    "features = titanic_without_na[features_cols]\n",
    "label = titanic_without_na[\"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já aplicamos o Scaler somente nas features para evitar que nossos algoritmos de machine learning se confundam quanto as proporções das features\n",
    "\n",
    "## <font color='blue'>Vocês conseguem aplicar StandardScaler nas features?</font>\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/atrasada-relogio-pulso-1116-1400x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução\n",
    "features_scaled = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente as **features** são chamadas de **X** e as **labels** são chamadas de **Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_teste, y_treino, y_teste = train_test_split(\n",
    "    features_scaled, label, test_size = 0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos validar os tamanhos das amostras geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De quebra ainda temos o conjunto de idade que devemos preencher usando **Regressão Linear**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_preencher = titanic[pandas.isnull(titanic[\"Age\"])].drop(\"Age\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear\n",
    "\n",
    "Método para aproximar duas variáveis linearmente (localização de imóvel vs preço, idade do carro vs preço). Dizemos que duas variáveis tem relação linear se plotarmos seus valores num gráfico e eles \"parecerem\" uma linha. Os passos para gerar uma regressão linear são 5:\n",
    "\n",
    "1. randomizar os inputs da função de hipotese\n",
    "2. computar o erro da predição (Mean Squared Error)\n",
    "3. Calcular as derivativas parciais\n",
    "4. Atualiazar os parametros baseados nas derivativas e na taxa de apredizado\n",
    "5. repetir do 2 ao 4 até o error ser o menor possivel.\n",
    "\n",
    "#### Função de Hipotese (Hypoteses Function)\n",
    "$ h0(x) = \\theta_1 + \\theta_0 == y = m(x) + b$\n",
    "\n",
    "é a função linear que vimos no primeiro grau da escola, o parâmetro $\\theta_1$ (m) define a angulação da linha e o $\\theta_0$ (b) define onde a linha cruza o eixo y.\n",
    "![](https://databootcamp.nyc3.digitaloceanspaces.com/img/regressao_linear.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o **Sklearn** podemos importar a Regressão Logística já implementada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar nossos dados de treino para treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = linear_reg.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predições são feitas com o dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = modelo.predict(x_teste)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos avaliar de forma simples usando o **score** do modelo. Ele usa um método chamado [**r2_score**](https://pt.wikipedia.org/wiki/Coeficiente_de_determina%C3%A7%C3%A3o) que é uma aproximação dos valores para ver se são similares. Esse método varia de 0 a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.score(x_teste, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem ruim essa predição... Podemos tentar melhorar ela um pouco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Features\n",
    "\n",
    "A etapa de seleção de features ajuda a reduzir o overfitting, aumenta a acurácia do modelo e reduz o tempo de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlação\n",
    "\n",
    "Vocês viram bastante sobre a importância de uso das correlações e seus tipos, elas são ótimas para filtrar as melhores colunas para usarmos.\n",
    "\n",
    "## <font color='blue'>Selecione as melhores features usando correlação</font>\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/atrasada-relogio-pulso-1116-1400x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE)\n",
    "\n",
    "Um algoritmo conhecido para seleção de features que faz uso da correlação por baixo dos panos é o RFE.\n",
    "\n",
    "Recursivamente vamos removendo uma a uma (ou de *step* em *step*) as features e vendo quais conseguem melhores resultados com os dados através da importância de cada feature no modelo. Conseguimos isso já implementado no **Sklearn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos escolher o número de passos (step) e o número de features que queremos usar. \"Chutei\" 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seletor = RFE(linear_reg, n_features_to_select=6, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos o treino normalmente com **fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected = seletor.fit(x_treino, y_treino)\n",
    "features_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como escolhemos 6 features, ele faz a melhor combinação de 6 features de acordo com nossos dados. Aonde está **True** significa que ele escolheu aquela feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver um Ranking de quão boas são as features também"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso temos como ver o *score* que vai transformar o dado para o número de features selecionados e aplicar o *score* do modelo de Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected.score(x_teste, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos automatizar isso para encontrar a melhor quantidade de features e as melhores combinações entre elas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_features = features_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "linhas = range(1, number_features + 1)\n",
    "for i in linhas:\n",
    "    seletor = RFE(linear_reg, n_features_to_select=i, step=1)\n",
    "    features_selected = seletor.fit(x_treino, y_treino)\n",
    "    resultado = features_selected.score(x_teste, y_teste)\n",
    "    scores.append(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o *pyploy* para ver esses dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(linhas, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos o melhor número de features em 6. Nossa predição parece continuar horrível... Não acertamos quase nada! A seleção de features serve somente para melhorar um pouco o que o modelo já tinha conseguido, mas normalmente não faz nenhum milagre.\n",
    "\n",
    "Pelo visto melhor continuar com nossa média dos sexos mesmo e seguir com nossos desafios!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos tentar prever quem vai sobreviver?\n",
    "\n",
    "<img src=\"https://databootcamp.nyc3.digitaloceanspaces.com/img/titanic-naufragio.webp\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Logística\n",
    "\n",
    "É uma técnica estatística que tem como objectivo produzir, a partir de um conjunto de observações, um modelo que permita a predição de valores tomados por uma variável categórica, frequentemente binária, a partir de uma série de variáveis explicativas contínuas e/ou binárias.\n",
    "\n",
    "Bem similar a Regressão linear, mas aplicamos uma função **sigmoid** no resultado para determinar em qual categoria se enquadra a classificação.\n",
    "\n",
    "![sigmoid](https://databootcamp.nyc3.digitaloceanspaces.com/img/sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No **Sklearn** temos a regressão logísica e vamos usá-la para tentar prever quem morreu ou sobreviveu no Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42, solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Agora Precisamos do nosso conjunto de treino e teste para o *Survived*</font>\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/atrasada-relogio-pulso-1116-1400x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução\n",
    "x_teste = x_treino = titanic.drop([\"Survived\", \"Age\"], axis=1)\n",
    "y_teste = y_treino = titanic[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo isso, só realizar o treino assim como na regressão linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = log_reg.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois disso conseguimos fazer as predições com o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_teste)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos as predições, mas como avaliar se elas são boas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de qualidade\n",
    "\n",
    "Devemos saber como medir a qualidade dos nossos modelos. No caso de modelos supervisionados, temos alguns métodos de validação que são bem conhecidos.\n",
    "\n",
    "### Matriz  de confusão\n",
    "\n",
    "A Matriz de Confusão é uma forma de mostrar mais claramente quantos são:\n",
    "- Verdadeiros Positivos (quem morreu e o modelo disse que morreu)\n",
    "- Falsos Positivos (quem não morreu e o modelo disse que morreu)\n",
    "- Verdadeiros Negativos (quem não morreu e o modelo disse que não morreu)\n",
    "- Falsos Negativos (quem morreu e o modelo disse que não morreu)\n",
    "\n",
    "![tt](https://sebastianraschka.com/images/faq/multiclass-metric/conf_mat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusao = pandas.crosstab(y_teste, predictions) # confusion_matrix\n",
    "matriz_confusao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision e recall\n",
    "\n",
    "A partir da matriz de confusão algumas taxas podem ser calculadas.\n",
    "\n",
    "Vamos visualizar de outra maneira os dados sendo testados:\n",
    "\n",
    "![pr](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Precis%C3%A3o_e_revoca%C3%A7%C3%A3o.png/262px-Precis%C3%A3o_e_revoca%C3%A7%C3%A3o.png)\n",
    "\n",
    "Dentro do círculo estão os elementos julgados como 1 (Positivo, nesse caso, sobreviveu).\n",
    "\n",
    "Fora do círculo estão os elementos que o algoritmo classificou como 0 (Negativo, nesse caso, não-sobreviveu).\n",
    "\n",
    "O retângulo representa o real valor dos dados.\n",
    "\n",
    "#### PRECISION\n",
    "\n",
    "*Precision* representa quanto dos elementos julgados como Sobreviventes, de fato são Sobreviventes. \n",
    "\n",
    "Mede a taxa de acerto do classificador dentre os valores <span class=\"atencao\">estimados</span> .\n",
    "\n",
    "$P=\\frac{TP}{TP+FP}$\n",
    "\n",
    "#### RECALL\n",
    "\n",
    "*Recall* representa quantos dos reais sobreviventes foram de fato classificados como sobreviventes.\n",
    "\n",
    "Mede a taxa de acerto do classificador dentre os valores <span class=\"atencao\">reais</span> .\n",
    "\n",
    "$R=\\frac{TP}{TP+FN}$\n",
    "\n",
    "#### F(Beta)-SCORE\n",
    "\n",
    "Podemos relacionar o *recall* e *precision* em uma métrica!\n",
    "\n",
    "![f_beta](https://databootcamp.nyc3.digitaloceanspaces.com/img/f_beta.svg)\n",
    "\n",
    "Com isso, temos o F1 que é o balanço exato entre *recall* e *precision*\n",
    "\n",
    "$F1=2\\frac{precision  \\times  recall}{precision+recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_teste, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso o f1 pode ser acessado através dessa função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_teste, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que é o mesmo que usar beta=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.fbeta_score(y_teste, predictions, beta=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Qual valor de Beta prioriza *precision*, 0,5 ou 2? Mostre</font>\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/atrasada-relogio-pulso-1116-1400x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "\n",
    "Outra técnica, a *Cross Validation*, ou validação cruzada, é muito usada para estimar a precisão de um modelo. \n",
    "\n",
    "A tecnica de *Cross Validation* pode ser usada também para otimização de parâmetros de um algoritmo. \n",
    "\n",
    "![cv](https://databootcamp.nyc3.digitaloceanspaces.com/img/cross_val.png)\n",
    "\n",
    "Com essa técnica passamos todo dataset de features e labels, e ela divide em k tamanhos nosso dado de forma aleatória treinando o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos Separar as **Features** e as **Labels** pensando no *Survived*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = titanic.drop([\"Survived\", \"Age\"], axis=1)\n",
    "labels = titanic[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso do **Sklearn** o **cv** é o parâmetro **k** de divisões do dataset. Aqui vamos dividir em 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "resultado = cross_validate(log_reg, features, labels, cv=10)\n",
    "mean_accuracy_test = sum(resultado[\"test_score\"])/len(resultado[\"test_score\"])\n",
    "\n",
    "print(f\"Média do teste: {mean_accuracy_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
