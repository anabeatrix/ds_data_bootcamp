{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado não-supervisionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "titanic = pandas.read_csv(\"https://databootcamp.nyc3.digitaloceanspaces.com/titanic_3.csv\")\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distâncias\n",
    "\n",
    "Vamos analisar o conceito de distância inicialmente! Esse conceito é usado por muitos dos algoritmos de aprendizado não supervisionado.\n",
    "\n",
    "Vamos imaginar um conjunto de dados que pode ser representado por dois valores numéricos, $X_1$ e $X_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver esses dados em um gráfico com os valores indicando suas posições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste = [[1,2],\n",
    "                [2,1],\n",
    "                [2,3.2],\n",
    "                [3,2.5],\n",
    "                [4,1],\n",
    "                [1.2,1],\n",
    "                [0.2,7.3]]\n",
    "\n",
    "dados = pandas.DataFrame(dados_teste,columns=[\"X1\", \"X2\"])\n",
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos colocar esses pontos em um gráfico para ilustrar como estão espalhados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(dados[\"X1\"], dados[\"X2\"], \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver visualmente que existe uma distância a ser medida entre esses pontos. Podemos medir essas distâncias de algumas formas. Vamos ver 2 delas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidiana\n",
    "\n",
    "A distância euclidiana é a distância direta entre dois pontos no espaço. Ela é bem útil para medir uma distância direta entre um ponto e outro e será usada no algoritmo KMeans que vamos ver a seguir.\n",
    "\n",
    "![euclidean](https://databootcamp.nyc3.digitaloceanspaces.com/img/distance.jpg)\n",
    "\n",
    "Quão mais perto de zero, menor a distância entre os pontos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso, com apenas duas colunas, podemos medir a distância entre dois pontos visualmente.\n",
    "A distância em linha reta desses pontos pode ser calculada a partir da fórmula da **distância euclidiana**\n",
    "\n",
    "$D(a,b) = \\sqrt{(a_{x1} - b_{x1})^2 + (a_{x2} - b_{x2})^2}$\n",
    "\n",
    "Vamos fazer então a função que calcula a distância euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a,b):\n",
    "    return ( (a[0]-b[0])**2 + (a[1]-b[1])**2 )**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dado_a = dados_teste[0]\n",
    "dado_b = dados_teste[2]\n",
    "d_ab = dist(dado_a,dado_b)\n",
    "\n",
    "print(f\"A distância de {dado_a} a {dado_b} é {d_ab}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse é o caso de um dado com dois atributos (duas dimensões). Podemos generalizar o cálculo para a quantidade de dimensões da coluna. A distância de duas colunas que tem $n$ atributos é\n",
    "\n",
    "$D(a,b) = \\sqrt{ \\sum_{i=1}^{n}{(a_{xi} - b_{xi})^2}}$\n",
    "\n",
    "Com isso conseguimos implementar essa generalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_n(a,b):\n",
    "    somatorio = 0.0\n",
    "    for i in range(len(a)):\n",
    "        somatorio = somatorio + (a[i]-b[i])**2\n",
    "    return somatorio**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para as mesmas listas temos uma distância zerada, pois são iguais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_n([1, 2],[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos validar a distância entre as nossas 2 colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_n(dados[\"X1\"], dados[\"X2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No **Sklearn** temos a distância euclidiana já implementada que é muito mais robusta que a nossa, mas ela espera que várias colunas sejam passadas, então precisamos passar uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import paired_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_distances([dados[\"X1\"]], [dados[\"X2\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Encontre a distância euclidiana entre a coluna *SibSp* e *Relatives* no Titanic</font>\n",
    "\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/atrasada-relogio-pulso-1116-1400x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosseno\n",
    "\n",
    "A similaridade entre os cossenos também é muito utilizada em muitos algoritmos de Machine Learning não supervisionados. Muitos deles normalmente algoritmos de recomendação.\n",
    "\n",
    "Diferente da distância euclidiana, essa métrica não está interessada na magnetude da distância, mas somente com a diferença dos ângulos dos vetores (que são suas colunas ou linhas).\n",
    "\n",
    "O que vemos normalmente é a similaridade dos cossenos e a distância nada mais é do que $1-similaridade$\n",
    "\n",
    "![similarity_cos](https://databootcamp.nyc3.digitaloceanspaces.com/img/cosine.png)\n",
    "\n",
    "Quão mais perto de zero, menor a distância entre os pontos, enquanto que mais perto de 1, maior a distância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como essa distância utiliza multiplicação matricial, utilizaremos o **Numpy** para ajudar a fazer a fórmula, primeiro da similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def cos_similaridade(a, b):\n",
    "    dot_product = numpy.dot(a, b)\n",
    "    norm_a = numpy.linalg.norm(a)\n",
    "    norm_b = numpy.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E depois a distância dos cossenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_distancia(a, b):\n",
    "    return 1 - cos_similaridade(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similaridade(dados[\"X1\"], dados[\"X2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_distancia(dados[\"X1\"], dados[\"X2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No **Sklearn** temos a distância dos cossenos já implementada também com a mesma função, mas usando o argumento de métrica como \"cosine\". Por padrão ele usa a euclidiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_distances([dados[\"X1\"]], [dados[\"X2\"]], \"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Encontre a distância dos cossenos entre a coluna *SibSp* e *Relatives* no Titanic</font>\n",
    "\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/atrasada-relogio-pulso-1116-1400x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "\n",
    "K-means é um algoritmo de agrupamento. A idéia é agrupar os dados por **proximidade** a um ponto central. Para falarmos sobre **proximidade** vamos aplicar os conceitos de **distância e similaridade** que vimos previamente. Ele usa um conceito de centróide que precisamos ver rapidamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideOutput": true
   },
   "source": [
    "\n",
    "### Centróide de um grupo\n",
    "\n",
    "**Centróide** é um ponto calculado que representa o centro do conjunto. \n",
    "\n",
    "Um cálculo normal de centroide a média dos atributos. \n",
    "\n",
    "Para entender melhor, vamos calcular o centroid dos dados de teste $X_1$ e $X_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o Método `mean()` da coluna para encontrar a média dos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_x1 = [dados[\"X1\"].mean()]\n",
    "centroid_x2 = [dados[\"X2\"].mean()]\n",
    "print(\"\"\"\n",
    "O centroid dos dados é [{},{}]\n",
    "\"\"\".format(centroid_x1,centroid_x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos plotar agora o grafico dos pontos para observar o posicionamento do centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(dados[\"X1\"],dados[\"X2\"],\"ob\")\n",
    "pyplot.plot(centroid_x1, centroid_x2, \"+r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece realmente representar o centro do conjunto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Faça uma função que calcule o centróide de todas as colunas do Titanic</font>\n",
    "![alt text](https://static.vix.com/pt/sites/default/files/styles/large/public/a/atrasada-relogio-pulso-1116-1400x800.jpg?itok=qv3gUH6U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução\n",
    "def centroide(df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroide(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Agora que sabemos encontrar o centróide de um conjunto, vamos ao conceito do algoritmo de `KMeans`!\n",
    "\n",
    "### O algortimo\n",
    "\n",
    "O objetivo do algoritmo é : Encontrar K clusters (agrupamentos) dos dados.\n",
    "\n",
    "Passo-a-passo: \n",
    "\n",
    "    1. Iniciamos K pontos aleatórios que serão considerados os centróides dos grupos.\n",
    "    \n",
    "    2. A matriz de distâncias é montada. \n",
    "    \n",
    "  Supondo que queremos montar `K` grupos e temos `n` dados \n",
    "    \n",
    "|       | $C_1$      | $C_2$      | ... |   $C_k$    |\n",
    "|-------|------------|------------|-----|------------|\n",
    "| $u_1$ |d($u_1$,$C_1$)|d($u_1$,$C_2$)| ... |d($u_1$,$C_k$)|\n",
    "| $u_2$ |d($u_2$,$C_1$)|d($u_2$,$C_2$)| ... |d($u_2$,$C_k$)|\n",
    "|  ...  |    ...     |     ...    | ... |     ...    |\n",
    "| $u_n$ |d($u_n$,$C_1$)|d($u_n$,$C_2$)| ... |d($u_n$,$C_k$)|\n",
    "\n",
    "   Cada dado $u_i$ é considerado do cluster com menor distância do centróide\n",
    "    \n",
    "    3. O Centróide real dos dados dos grupos é calculado\n",
    "   \n",
    "    4. A matriz de distância é feita de novo, considerando os centroides calculados no passo 3.\n",
    "       \n",
    "       4.1 . Se algum dado mudar de cluster, o algoritmo volta ao passo 2, considerando esses centroides como os K centroides \n",
    "       \n",
    "       4.2 . Se nenhum dado mudar de cluster, o algoritmo assume que encontrou os clusters!\n",
    "\n",
    "\n",
    "![kmeans](https://databootcamp.nyc3.digitaloceanspaces.com/img/K-means_convergence.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora criar os cluster dos dados fictícios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "model = kmeans.fit(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora pegar os centróides do modelo e plotar. O **T** é usado para transpor nosso conjunto de dados para facilitar o plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = model.cluster_centers_\n",
    "c_to_plot = centers.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(dados[\"X1\"],dados[\"X2\"],'ob')\n",
    "pyplot.plot(c_to_plot[0],c_to_plot[1],'or')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora que já vimos como o KMeans funciona, vamos aplicar para um problema real!\n",
    "\n",
    "Vamos tentar verificar se podemos clusterizar os tripulantes do Titanic escolhendo algumas Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "        \"Pclass\",\n",
    "        \"Sex\",\n",
    "        \"SibSp\",\n",
    "        \"Parch\",\n",
    "        \"Relatives\",\n",
    "        \"Embarked\",\n",
    "        \"Survived\",\n",
    "        \"Fare\"\n",
    "    ]\n",
    "feature_df = pandas.get_dummies(titanic[features])\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vamos precisar do Scaler também. Precisamos do Scaler porque a medida de distância é muito afetada se não padronizarmos os números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar com 4 clusters igual fizemos anteriormente com: criança, adolescente, adulto, idoso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = scaler.fit_transform(feature_df)\n",
    "predictions = kmeans.fit_predict(scaled_df)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso conseguimos os Clusters que o algoritmo predice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas será que isso está certo? Vamos avaliar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas\n",
    "\n",
    "Precisamos saber metrificar os algoritmos não supervisionados também. Como não temos um parâmetro de verdade, as métricas usam outros parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inércia\n",
    "\n",
    "A inércia é a métrica mais conhecida de clusters. Ela mede o quão distante os pontos estão do centróides em um cluster. Quão mais próximo de zero, melhor é sua clusterização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para avaliar isso, precisamos olhar no resultado do KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse valor parece meio alto... Será que realmente é a melhor quantidade de clusters? Para isso temos o método de **Elbow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow\n",
    "\n",
    "Método que visa encontrar a melhor quantidade de clusters para um problema. Com isso você pode avaliar se o seu número de clusters realmente era bom. A idea dele é simplesmente iterar sobre vários números possíveis de cluster e avaliar se o valor de **Inércia** cai. A melhor quantidade de clusters normalmente é aonde aparece o \"cotovelo\" (Elbow) do gráfico.\n",
    "\n",
    "![elbow](https://databootcamp.nyc3.digitaloceanspaces.com/img/elbow.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inercias = []\n",
    "clusters = range(2, 50)\n",
    "for k in clusters:\n",
    "    scaler = StandardScaler()\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit_predict(\n",
    "        scaler.fit_transform(feature_df)\n",
    "    )\n",
    "    inercias.append(kmeans.inertia_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo calculado os valores de Inércia podemos plotar e descobrir um bom cotovelo (Elbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(clusters, inercias, \"o\")\n",
    "pyplot.grid(True)\n",
    "pyplot.title('Elbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente esse método é bem subjetivo mesmo e podemos ver um bom valor entre 10 e 20 clusters se formos tentar dividir os tripulantes. Mas está bastante subjetivo... Um método mais objetivo é o da Silhueta (**Silhouette**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette\n",
    "\n",
    "A Silhueta mede o quanto valores de um cluster estão distantes do outro cluster\n",
    "O valor de Silhueta tem máximo e mínimo, sendo -1 o pior e 1 o melhor. Com isso, conseguimos entender melhor se um resultado é bom ou não.\n",
    "\n",
    "Na fórmula, *a* é a média da distância dentro de um cluster dos outros pontos no mesmo cluster e *b* é a menor distância entre um ponto de um cluster de qualquer outro cluster.\n",
    "\n",
    "$S(i) = (b(i) - a(i)) / max(a(i), b(i))$\n",
    "\n",
    "Isso é feito para cada ponto *i*.\n",
    "\n",
    "Podemos tentar encontrar o melhor número de clusters usando essa métrica para validar dentro do intervalo que encontramos em **Elbow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhuetas = []\n",
    "clusters = range(10, 21)\n",
    "for k in clusters:\n",
    "    scaler = StandardScaler()\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    predicted = kmeans.fit_predict(\n",
    "        scaler.fit_transform(feature_df)\n",
    "    )\n",
    "    score = silhouette_score(feature_df, predicted)\n",
    "    silhuetas.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(clusters, silhuetas)\n",
    "pyplot.grid(True)\n",
    "pyplot.title('Silhouette and Inertia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor valor parece ser realmente com 14 clusters! Mas mesmo assim ainda está bem ruim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Vamos usar KMeans para ver quem sobrevive ou não no Titanic!</font>\n",
    "\n",
    "Vamos tentar usar 2 clusters e prever se vive ou não... Será que funciona?\n",
    "![alt text](https://databootcamp.nyc3.digitaloceanspaces.com/img/atrasada-relogio-pulso-1116-1400x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
